{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/FvSXwwJh27rm6NhS6HzR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 혁신의 숲 크롤링"],"metadata":{"id":"La2Y3RcUc5oj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RcusLx_cvQK"},"outputs":[],"source":["#패키지 설치\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.common.keys import Keys\n","\n","import re\n","import time\n","import datetime\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["#셀레니움 열기\n","path=r'C:\\Users\\NTX550\\Desktop\\chromedriver-win64\\chromedriver.exe'\n","\n","s=Service(path)\n","driver=webdriver.Chrome(service=s)\n","driver.set_window_size(700,700)"],"metadata":{"id":"RtP7XZdec-dg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#저장할 데이터와 코드를 읽을 수 있는 파일 열기\n","df=pd.read_excel('Company_code.xlsx')\n","df.drop(['Unnamed: 0'],axis=1,inplace=True)\n","df2=pd.read_excel('THOUSAND_7.xlsx')\n","df2.drop(['Unnamed: 0'],axis=1,inplace=True)\n","df2.head()"],"metadata":{"id":"SjyPyNv1c-45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#크롤링\n","for idx in range(len(df)):\n","\n","    if idx % 200 == 0:\n","        df2.to_excel(f\"temp{idx}.xlsx\")\n","    print(idx)\n","    print(df.at[idx,'code'])\n","    code=df.at[idx,'code']\n","    url=f'https://www.innoforest.co.kr/company/{code}'\n","    driver.get(url)\n","    time.sleep(3)\n","\n","    soup=BeautifulSoup(driver.page_source)\n","\n","\n","    #기업정보\n","    info=soup.find('div',class_='css-4q8h6z')\n","    a=info.find_all('div',class_='css-198bnr5')\n","    c=['listed','operation','make_date','homepage','address']\n","    for i in range(len(c)):\n","        if len(c)!=len(a):\n","            error.append(code)\n","        else:\n","            df2.at[idx,c[i]]=a[i].find('dd').text\n","            print(a[i].find('dd').text)\n","\n","\n","    #임직원\n","    df2.at[idx,'name']=''\n","    df2.at[idx,'link']=''\n","\n","    cla=['css-1ya8xf7']\n","    for i in range(len(cla)):\n","        a=soup.find('div',class_=cla[i]).text\n","        df2.at[idx,'name']=a.split('*')[0]\n","        b=''\n","        if soup.find('div',class_=cla[i]).find('a'):\n","            b=soup.find('div',class_=cla[i]).find('a').get('href')\n","            df2.at[idx,'link']=b\n","\n","\n","\n","    #주요정보\n","    main=soup.find('dl',class_='css-1lhycl7').find_all('dd',class_='css-ol6q4q')\n","    #자본금,고용인원,누적투자유치금액,투자유치횟수,연매출,기술등급\n","    c2=['seed','employer','acc_invest','cnt_invest','year_sales','tech_rank']\n","    for i in range(len(main)):\n","        #자본금\n","        fin=main[i].text\n","        df2.at[idx,c2[i]]=main[i].text\n","\n","\n","    #기업설명\n","    df2.at[idx,'Company_explain']=info.find('p').text\n","\n","    #검은색해시태그\n","    df2.at[idx,'Main_keyword']=''\n","    black=info.find_all('span',class_='css-1t6caqs')\n","    blackhash=[]\n","    for i in range(len(black)):\n","        a=info.find_all('span',class_='css-1t6caqs')[i].text\n","        for j in range(len(a)):\n","            if a[j].isdigit():\n","                if j==len(a):\n","                    break\n","                elif a[j+1].isdigit():\n","                    break\n","        blackhash.append(a[:j])\n","    print(blackhash)\n","    df2.at[idx,'Main_keyword']=blackhash\n","\n","    #하얀색 해시태그\n","    df2.at[idx,'other_keyword']=''\n","    grey=info.find_all('span',class_='css-184w0e7')\n","    greyhash=[]\n","    for i in range(len(grey)):\n","        a=info.find_all('span',class_='css-184w0e7')[i].text\n","        for j in range(len(a)):\n","            if a[j].isdigit():\n","                if j==len(a)-1:\n","                    break\n","                elif a[j+1].isdigit():\n","                    break\n","        greyhash.append(a[:j])\n","    df2.at[idx,'other_keyword']=greyhash\n","    print(greyhash)\n","    print('*'*50)"],"metadata":{"id":"C2kharZsdAbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#파일저장\n","df2.to_excel('Info_company.xlsx')"],"metadata":{"id":"QZdThaMrdHAr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 빅카인즈 크롤링"],"metadata":{"id":"Wjj7U_iOdKc2"}},{"cell_type":"code","source":["#패키지 설치\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.common.keys import Keys\n","\n","import re\n","import time\n","import datetime\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"nMkD-0PbdRIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_excel('temp1.xlsx')\n","df.drop(['Unnamed: 0'],axis=1,inplace=True)"],"metadata":{"id":"obSQV7bydRv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#셀레니움 열기\n","path=r'C:\\Users\\NTX550\\Desktop\\chromedriver-win64\\chromedriver.exe'\n","\n","s=Service(path)\n","driver=webdriver.Chrome(service=s)\n","driver.set_window_size(700,700)"],"metadata":{"id":"NssBzoXqdWRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5000,5500):\n","    #페이지 열기\n","    url='https://www.bigkinds.or.kr/v2/news/index.do'\n","    driver.get(url)\n","    time.sleep(1)\n","\n","    #검색어\n","    query_txt=df.at[i,'Company']\n","\n","    #검색어 입력할 곳\n","    element=driver.find_element(By.XPATH,'//*[@id=\"total-search-key\"]')\n","\n","    #검색어 입력\n","    element.send_keys(query_txt)\n","\n","    #검색어 찾기\n","    element.send_keys(Keys.ENTER)\n","    #btn_path='//*[@id=\"search-foot-div\"]/div[2]/button[2]'\n","    #driver.find_element(By.XPATH,btn_path).click()\n","\n","    time.sleep(2)\n","    #건수\n","    soup=BeautifulSoup(driver.page_source)\n","    df.at[i,'news']=int(soup.find('span',class_='total-news-cnt').text.replace(',',''))\n","    #p='//*[@id=\"news-results-tab\"]/div[3]/h3/span[6]'\n","    #df.at[i,'news']=driver.find_element(By.XPATH,p).text\n","    print(i,(soup.find('span',class_='total-news-cnt').text).replace(',',''))"],"metadata":{"id":"1NJe7EsHdZ-Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_excel('temp.xlsx')"],"metadata":{"id":"O5lPIUa3dkwQ"},"execution_count":null,"outputs":[]}]}